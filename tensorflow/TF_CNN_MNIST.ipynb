{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-CNN-MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQy5qe4AIjVkPndIomvRfy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theAkhileshRai/DeepLearning/blob/master/tensorflow/TF_CNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEL9Nwm8oRKO",
        "colab_type": "code",
        "outputId": "552ee10e-488d-4bc1-d642-2d5fa7c19875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "! pip install tensorflow==1.3"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.3 in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (1.18.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (0.34.2)\n",
            "Requirement already satisfied: tensorflow-tensorboard<0.2.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (0.1.8)\n",
            "Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (3.10.0)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (1.5.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (1.0.1)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (0.9999999)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (3.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.3) (46.1.3)\n",
            "Requirement already satisfied: tensorflow==1.3 in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (1.18.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-tensorboard<0.2.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (0.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.3) (46.1.3)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (1.5.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (1.0.1)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (0.9999999)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (3.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG1F7UVyoVOF",
        "colab_type": "code",
        "outputId": "ceddaa24-acd4-43de-9b19-48ef8a1e1dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34dMUtD2o3ZL",
        "colab_type": "code",
        "outputId": "8fd35443-f9c8-4f0b-894d-a27df0616df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot = True)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p6s8k7cpFTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#HELPER\n",
        "#INIT WEIGHT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpJW2RcOpLYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(shape):\n",
        "  init_random_dist = tf.truncated_normal(shape,stddev=0.1)\n",
        "\n",
        "  return tf.Variable(init_random_dist)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeR_C8kQpoQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#INIT BIAS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P62LuqqgppQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_bias(shape):\n",
        "  init_bias = tf.constant(0.1,shape=shape)\n",
        "  return tf.Variable(init_bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCDGi-cqpteq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CONV2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u7A2J07qHD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(x,W):\n",
        "  #x --> data shape(B,H,W,C)\n",
        "  #w --> weight shape(H,W,Cin,Cout)\n",
        "\n",
        "  return tf.nn.conv2d(x,W,strides = [1,1,1,1],padding='SAME')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhYRxs1Jq9Xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#POOLING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVaSp84xq-6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxpooling2by2(x):\n",
        "  return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gOsYegSrmed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CONVOLUTIONAL LAYER\n",
        "def convolution_layer(input_x,shape):\n",
        "  W = init_weights(shape)\n",
        "  b = init_bias([shape[3]])\n",
        "\n",
        "  return tf.nn.relu(conv2d(input_x,W)+b)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZMds1Y8syJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FULLY CONNECTED\n",
        "def normal_full_layer(input_layer,size):\n",
        "  input_size = int(input_layer.get_shape()[1])\n",
        "  W = init_weights([input_size,size])\n",
        "  b = init_bias([size])\n",
        "\n",
        "  return tf.matmul(input_layer,W) + b\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY5OCnpwisea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32,shape = [None,784])\n",
        "y_true = tf.placeholder(tf.float32,shape=[None,10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZvhzVrhj2I0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_image = tf.reshape(x,[-1,28,28,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbgxslwZleKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convo_1 = convolution_layer(x_image,shape = [5,5,1,32])\n",
        "convo_1_pooling = maxpooling2by2(convo_1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePCSoczym65T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convo_2 = convolution_layer(convo_1_pooling,shape = [5,5,32,64])\n",
        "convo_2_pooling = maxpooling2by2(convo_2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVqdHWGGvNZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "convo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj3bifXquUFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fully_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))\n",
        "#DROPOUT\n",
        "hold_prob = tf.placeholder(tf.float32)\n",
        "full_one_dropout = tf.nn.dropout(fully_layer_one,keep_prob=hold_prob)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzVMD0ds08Gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = normal_full_layer(full_one_dropout,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5VhMvOu1kLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = y_true,logits= y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4kH4W142AiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYDezm5f2uXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guRYVqvU2e4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init =  tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LLTBg1p25TO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9be50bb3-f0de-4ca5-bb38-3050a2dc3a7a"
      },
      "source": [
        "steps = 2000\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "  sess.run(init)\n",
        "\n",
        "  for i in range(steps):\n",
        "\n",
        "    batch_x,batch_y = mnist.train.next_batch(50)\n",
        "    sess.run(train,feed_dict = {x:batch_x,y_true:batch_y,hold_prob:0.5})\n",
        "\n",
        "    if i%100 == 0:\n",
        "      print('Steps:{}'.format(i))\n",
        "      print('Accuracy:')\n",
        "      matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
        "      accuracy = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "      print(sess.run(accuracy,feed_dict = {x:mnist.test.images,y_true:mnist.test.labels,hold_prob:1.0}))\n",
        "      print('\\n')      "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps:0\n",
            "Accuracy:\n",
            "0.1109\n",
            "\n",
            "\n",
            "Steps:100\n",
            "Accuracy:\n",
            "0.942\n",
            "\n",
            "\n",
            "Steps:200\n",
            "Accuracy:\n",
            "0.9639\n",
            "\n",
            "\n",
            "Steps:300\n",
            "Accuracy:\n",
            "0.9699\n",
            "\n",
            "\n",
            "Steps:400\n",
            "Accuracy:\n",
            "0.9763\n",
            "\n",
            "\n",
            "Steps:500\n",
            "Accuracy:\n",
            "0.9804\n",
            "\n",
            "\n",
            "Steps:600\n",
            "Accuracy:\n",
            "0.9845\n",
            "\n",
            "\n",
            "Steps:700\n",
            "Accuracy:\n",
            "0.9821\n",
            "\n",
            "\n",
            "Steps:800\n",
            "Accuracy:\n",
            "0.9826\n",
            "\n",
            "\n",
            "Steps:900\n",
            "Accuracy:\n",
            "0.9821\n",
            "\n",
            "\n",
            "Steps:1000\n",
            "Accuracy:\n",
            "0.9853\n",
            "\n",
            "\n",
            "Steps:1100\n",
            "Accuracy:\n",
            "0.984\n",
            "\n",
            "\n",
            "Steps:1200\n",
            "Accuracy:\n",
            "0.9867\n",
            "\n",
            "\n",
            "Steps:1300\n",
            "Accuracy:\n",
            "0.9865\n",
            "\n",
            "\n",
            "Steps:1400\n",
            "Accuracy:\n",
            "0.9871\n",
            "\n",
            "\n",
            "Steps:1500\n",
            "Accuracy:\n",
            "0.9874\n",
            "\n",
            "\n",
            "Steps:1600\n",
            "Accuracy:\n",
            "0.9866\n",
            "\n",
            "\n",
            "Steps:1700\n",
            "Accuracy:\n",
            "0.9873\n",
            "\n",
            "\n",
            "Steps:1800\n",
            "Accuracy:\n",
            "0.9893\n",
            "\n",
            "\n",
            "Steps:1900\n",
            "Accuracy:\n",
            "0.9903\n",
            "\n",
            "\n",
            "Steps:0\n",
            "Accuracy:\n",
            "0.2416\n",
            "\n",
            "\n",
            "Steps:100\n",
            "Accuracy:\n",
            "0.9324\n",
            "\n",
            "\n",
            "Steps:200\n",
            "Accuracy:\n",
            "0.9587\n",
            "\n",
            "\n",
            "Steps:300\n",
            "Accuracy:\n",
            "0.9691\n",
            "\n",
            "\n",
            "Steps:400\n",
            "Accuracy:\n",
            "0.9724\n",
            "\n",
            "\n",
            "Steps:500\n",
            "Accuracy:\n",
            "0.9745\n",
            "\n",
            "\n",
            "Steps:600\n",
            "Accuracy:\n",
            "0.98\n",
            "\n",
            "\n",
            "Steps:700\n",
            "Accuracy:\n",
            "0.9806\n",
            "\n",
            "\n",
            "Steps:800\n",
            "Accuracy:\n",
            "0.9803\n",
            "\n",
            "\n",
            "Steps:900\n",
            "Accuracy:\n",
            "0.9814\n",
            "\n",
            "\n",
            "Steps:1000\n",
            "Accuracy:\n",
            "0.9837\n",
            "\n",
            "\n",
            "Steps:1100\n",
            "Accuracy:\n",
            "0.9867\n",
            "\n",
            "\n",
            "Steps:1200\n",
            "Accuracy:\n",
            "0.9866\n",
            "\n",
            "\n",
            "Steps:1300\n",
            "Accuracy:\n",
            "0.9868\n",
            "\n",
            "\n",
            "Steps:1400\n",
            "Accuracy:\n",
            "0.9869\n",
            "\n",
            "\n",
            "Steps:1500\n",
            "Accuracy:\n",
            "0.9885\n",
            "\n",
            "\n",
            "Steps:1600\n",
            "Accuracy:\n",
            "0.9858\n",
            "\n",
            "\n",
            "Steps:1700\n",
            "Accuracy:\n",
            "0.9878\n",
            "\n",
            "\n",
            "Steps:1800\n",
            "Accuracy:\n",
            "0.9884\n",
            "\n",
            "\n",
            "Steps:1900\n",
            "Accuracy:\n",
            "0.9885\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}